{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findq2(expout,prdout):\n",
    "\n",
    "   nSamples = expout.size;\n",
    "\n",
    "   sum1 = 0\n",
    "   for i in range(1,nSamples):\n",
    "       c = expout[i]-prdout[i]\n",
    "       d = np.square(c)\n",
    "       sum1 = sum1 + d\n",
    "        \n",
    "   sum2 = 0\n",
    "   e = np.mean(expout)\n",
    "   for i in range(1,nSamples):\n",
    "       f = expout[i] - e\n",
    "       g = np.square(f)\n",
    "       sum2 = sum2 + g\n",
    "        \n",
    "   q2 = 1-(sum1/sum2)     \n",
    "   \n",
    "   return q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussmf(x,sigma,c):\n",
    "    dividend = -1*np.square(x - c)\n",
    "    divisor = 2*np.square(sigma)\n",
    "    quotient = dividend/divisor;\n",
    "    y=np.exp(quotient)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainfsvm(X,y,M,sigma,ker,svrc,svrp):\n",
    "   # L is the number of data samples\n",
    "   L=X.shape[0] #gives number of row count\n",
    "   # m is the number of rules\n",
    "   m=M.shape[0]\n",
    "   # n is the number of features\n",
    "   n=X.shape[1] #gives number of col count\n",
    "   \n",
    "   out = [] # from copy\n",
    "    \n",
    "   trn_labels = y;\n",
    "   trn_features = np.zeros((L,m*(n+1)))\n",
    "    \n",
    "   trnA = np.zeros((L,m*(n+1)))\n",
    "   weights = np.zeros((L,m))\n",
    "    \n",
    "   itermax = 1\n",
    "\n",
    "   for iter in range(0,itermax):\n",
    "       for i in range(0,L):\n",
    "           U=[]\n",
    "           for j in range(0,m):\n",
    "               u=1\n",
    "               for t in range(0,n):\n",
    "                   u=u*(gaussmf(X[t][i],sigma[t][j],M[t][j]))\n",
    "               U=U+[u]\n",
    "           fa=U/sum(U) # this is the weight\n",
    "           row = np.append(X.iloc[[i]].values,1)\n",
    "           xtemp = np.zeros(shape=(fa.size,row.size))\n",
    "           for ii in range(0,fa.size):\n",
    "               for jj in range(0,row.size):\n",
    "                   xtemp[ii][jj]= fa[ii]*row[jj]\n",
    "           xtemp=np.reshape(xtemp, fa.size*row.size)\n",
    "           trnA.transpose()[:,i] = xtemp;\n",
    "           weights.transpose()[:,i] = fa;\n",
    "       trn_features = trnA; # X #trn_labels = y\n",
    "       clf = svr(kernel=ker, C=svrc, epsilon=svrp)\n",
    "       clf.fit(trn_features, trn_labels)\n",
    "       w=np.dot(clf.support_vectors_.transpose(),clf.dual_coef_.transpose())\n",
    "       bias = clf.intercept_\n",
    "       C = np.reshape(w,(m,n+1))\n",
    "       C = pd.DataFrame(C)\n",
    "   return clf, C, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictfsvm(X,y,M,sigma,C,bias):   \n",
    "   # L is the number of data samples\n",
    "   L=X.shape[0] #gives number of row count\n",
    "   # m is the number of rules\n",
    "   m=M.shape[0]\n",
    "   # n is the number of features\n",
    "   n=X.shape[1] #gives number of col count\n",
    "   \n",
    "   out = []\n",
    "   labels = y;\n",
    "\n",
    "   for i in range(0,L):\n",
    "       U=[]\n",
    "       #print \"i=\"+str(i)\n",
    "       for j in range(0,m):\n",
    "           u=1\n",
    "           for t in range(0,n):\n",
    "               u=u*(gaussmf(X[t][i],sigma[t][j],M[t][j]))\n",
    "           U=U+[u];\n",
    "           #print \"j=\"+str(j)+\" \"+\"U=\"+str(U)\n",
    "       fa=U/sum(U); # this is the weight    \n",
    "       c0=C[n]\n",
    "       for t in range(0,n):\n",
    "           c0=c0+C[t]*X[t][i] # calculating y for each rule\n",
    "       c0=c0.as_matrix()\n",
    "       f=np.dot(fa,c0) + bias\n",
    "       out = out + [f]\n",
    "   return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The inital set of amino acids and their numerical values\n",
    "def aa2int(aa):\n",
    "    aalist = \"ARNDCQEGHILKMFPSTWYVBZX*-\"\n",
    "    aalist = list(aalist)\n",
    "    return aalist.index(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pep2mat(peptides):\n",
    "    list_of_peptides = list(peptides)\n",
    "    num_of_peptides = len(list_of_peptides)\n",
    "    pepsize = len(list_of_peptides[0])\n",
    "    matrix = np.ones((num_of_peptides,pepsize))\n",
    "    for i in range(num_of_peptides):\n",
    "        peptide = list(list_of_peptides[i])\n",
    "        for j in range(pepsize):\n",
    "            matrix[i,j] = aa2int(peptide[j])\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def peptide2scales(numPeptides,nFeatures):\n",
    "    nSamples = numPeptides.shape[0]\n",
    "    nAA = numPeptides.shape[1]\n",
    "    datin = -1*np.ones((nSamples,nFeatures*nAA))\n",
    "    for i in range(nSamples):\n",
    "        for j in range(nAA):\n",
    "            aa = int(numPeptides[i,j])\n",
    "            for k in range(nFeatures):\n",
    "                idx = j*nFeatures + k\n",
    "                datin[i,idx] = scales[k,aa]\n",
    "    return pd.DataFrame(datin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR as svr\n",
    "from sklearn.preprocessing import MinMaxScaler as mmscaler\n",
    "from sklearn.feature_selection import VarianceThreshold as vt\n",
    "import skfuzzy as fuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### LOAD AA SCALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# min-max normalized from coepra-scales-2.csv\n",
    "scaler = mmscaler()\n",
    "df_coeprascales2=pd.read_csv(\"data/coepra-scales-2.csv\",header=None); # (643x20)\n",
    "np_coeprascales2=np.array(df_coeprascales2.transpose())\n",
    "scaler.fit(np_coeprascales2)\n",
    "np_coeprascales2 = scaler.transform(np_coeprascales2)\n",
    "df_scales = pd.DataFrame(np_coeprascales2)\n",
    "df_scales = df_scales.transpose() # (643x20)\n",
    "scales = np.array(df_scales)\n",
    "nFeatures = scales.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### SELECTED PARAMETER SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {'cnum':2, 'svrc':1.0, 'svrp':0.05, 'threshold':0.91}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### LOAD TRAIN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"data/task1trnpep.txt\", sep=' ', header=None)\n",
    "txtPeptides = data[0]\n",
    "numPeptides = pep2mat(txtPeptides); # n: make numerical\n",
    "ytrain=pd.DataFrame(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trnin=peptide2scales(numPeptides,nFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SELECTED FEATURE SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#selfea=pd.read_csv(\"task1env/selfea.dat\",header=None)\n",
    "#selfea = selfea.transpose().values[0]-1\n",
    "#numInp=len(selfea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SELECTED FEATURE SET WITH VARIENCETHRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1049"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvalue = float(param['threshold'])\n",
    "selector = vt(threshold=(tvalue * (1 - tvalue)))\n",
    "selector.fit_transform(trnin)\n",
    "selidx = selector.get_support(indices=True)\n",
    "selfea = selidx\n",
    "numInp=len(selidx)\n",
    "len(selidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain = trnin.as_matrix()[:,selfea.tolist()]\n",
    "Xtrain = pd.DataFrame(Xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### FUZZY C MEANS CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameter identification: (mean)\n",
    "trndat = pd.concat([Xtrain, ytrain], axis=1, ignore_index=True) # input ve output beraber cluster edilcek.\n",
    "# error 0.005 and maxiter=1000 are skfuzzy parameters\n",
    "# error 0.00001 and maxiter=100 are matlab parameters\n",
    "ctr, U, u0, d, jm, p, fpc = fuzz.cluster.cmeans(trndat.transpose(), param['cnum'], 2, error=0.005, maxiter=1000, init=None)\n",
    "M = ctr[:, 0:numInp] # Antecedent Mean (M)\n",
    "M = pd.DataFrame(np.round(M,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameter identification: (stddev)\n",
    "inpstd = np.zeros((param['cnum'],numInp)) #stddev\n",
    "for i in range(0,param['cnum']):\n",
    "    u = U[i] # u is the membership values of data samples to the next cluster\n",
    "    v = M.as_matrix()[i] # v is the mean values of the next cluster | cl.center >> ctr\n",
    "    n = Xtrain.shape[0] # n is the number of data\n",
    "    numInp = Xtrain.shape[1] # number of inputs\n",
    "    diff = np.zeros((n,numInp))\n",
    "    suu = 0 # sum of u\n",
    "    \n",
    "    # https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.ndarray.html\n",
    "    for j in range(0,n):\n",
    "        diff[j] = Xtrain.as_matrix()[j]-v\n",
    "\n",
    "    for j in range(0,n):\n",
    "        suu = suu + u[j]**1\n",
    "\n",
    "    val = np.dot((diff**2).transpose(),(u**1).transpose())/suu # val is the variable for variance\n",
    "    val = val.transpose() # (vuvar2)\n",
    "    \n",
    "    inpstd[i] = np.sqrt(val) # Antecedent S\n",
    "    inpstd[i] = np.round(inpstd[i],4)\n",
    "inpstd = pd.DataFrame(inpstd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### TRAINING FUZZY SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf:SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.05, gamma='auto',\n",
      "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "bias:[ 2.24331597]\n"
     ]
    }
   ],
   "source": [
    "ker = 'linear'\n",
    "clf,C,bias = trainfsvm(Xtrain,ytrain.values.ravel(),M,inpstd,ker,param['svrc'],param['svrp'])\n",
    "print('clf:'+str(clf))\n",
    "print('bias:'+str(bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### PREDICTING TRAIN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trnq2:[ 0.8303421]\n"
     ]
    }
   ],
   "source": [
    "expout = ytrain.as_matrix()\n",
    "prdout = predictfsvm(Xtrain,ytrain,M,inpstd,C,bias)\n",
    "trnq2 = findq2(expout,prdout)\n",
    "print('trnq2:'+str(trnq2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### LOAD TEST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"data/task1tstpep.txt\", sep=' ', header=None)\n",
    "txtPeptides = data[0]\n",
    "numPeptides = pep2mat(txtPeptides); # n: make numerical\n",
    "ytest=pd.DataFrame(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chkin=peptide2scales(numPeptides,nFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtest = chkin.as_matrix()[:,selfea.tolist()]\n",
    "Xtest = pd.DataFrame(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### PREDICTING TEST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chkq2:[ 0.59570994]\n"
     ]
    }
   ],
   "source": [
    "expout = ytest.as_matrix()\n",
    "prdout = predictfsvm(Xtest,ytest,M,inpstd,C,bias)\n",
    "chkq2 = findq2(expout,prdout)\n",
    "print('chkq2:'+str(chkq2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trnq2:[ 0.8303421]\n",
      "chkq2:[ 0.59570994]\n"
     ]
    }
   ],
   "source": [
    "print('trnq2:'+str(trnq2))\n",
    "print('chkq2:'+str(chkq2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### REPEATPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeatprocess(param):\n",
    "    # parameter identification: (mean)\n",
    "    trndat = pd.concat([Xtrain, ytrain], axis=1, ignore_index=True) # input ve output beraber cluster edilcek.\n",
    "    ctr, U, u0, d, jm, p, fpc = fuzz.cluster.cmeans(trndat.transpose(), param['cnum'], 2, error=0.005, maxiter=1000, init=None)\n",
    "    M = ctr[:, 0:param['numInp']] # Antecedent Mean (M)\n",
    "    M = pd.DataFrame(np.round(M,4))\n",
    "    \n",
    "    # parameter identification: (stddev)\n",
    "    inpstd = np.zeros((param['cnum'],param['numInp'])) #stddev\n",
    "    for i in range(0,param['cnum']):\n",
    "        u = U[i] # u is the membership values of data samples to the next cluster\n",
    "        v = M.as_matrix()[i] # v is the mean values of the next cluster | cl.center >> ctr\n",
    "        n = Xtrain.shape[0] # n is the number of data\n",
    "        numInp = Xtrain.shape[1] # number of inputs\n",
    "        diff = np.zeros((n,param['numInp']))\n",
    "        suu = 0 # sum of u\n",
    "\n",
    "        # https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.ndarray.html\n",
    "        for j in range(0,n):\n",
    "            diff[j] = Xtrain.as_matrix()[j]-v\n",
    "\n",
    "        for j in range(0,n):\n",
    "            suu = suu + u[j]**1\n",
    "\n",
    "        val = np.dot((diff**2).transpose(),(u**1).transpose())/suu # val is the variable for variance\n",
    "        val = val.transpose() # (vuvar2)\n",
    "\n",
    "        inpstd[i] = np.sqrt(val) # Antecedent S\n",
    "        inpstd[i] = np.round(inpstd[i],4)\n",
    "    inpstd = pd.DataFrame(inpstd)\n",
    "    \n",
    "    ker = 'linear'\n",
    "    clf,C,bias = trainfsvm(Xtrain,ytrain.values.ravel(),M,inpstd,ker,param['svrc'],param['svrp'])\n",
    "    \n",
    "    expout = ytrain.as_matrix()\n",
    "    prdout = predictfsvm(Xtrain,ytrain,M,inpstd,C,bias)\n",
    "    trnq2 = findq2(expout,prdout)\n",
    "    \n",
    "    expout = ytest.as_matrix()\n",
    "    prdout = predictfsvm(Xtest,ytest,M,inpstd,C,bias)\n",
    "    chkq2 = findq2(expout,prdout) \n",
    "\n",
    "    paramnew = param.copy()\n",
    "    paramnew['bias'] = float(np.round(bias,decimals=3))\n",
    "    paramnew['trnq2'] = float(np.round(trnq2,decimals=3))\n",
    "    paramnew['chkq2'] = float(np.round(chkq2,decimals=3))\n",
    "        \n",
    "    return paramnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trnq2': 0.529, 'cnum': 2, 'chkq2': 0.436, 'bias': 2.791, 'svrp': 0.050000000000000003, 'threshold': 0.80000000000000004, 'numInp': 87, 'svrc': 2.1000000000000001}\n",
      "0\n",
      "{'trnq2': 0.529, 'cnum': 2, 'chkq2': 0.439, 'bias': 2.74, 'svrp': 0.050000000000000003, 'threshold': 0.80000000000000004, 'numInp': 87, 'svrc': 2.2000000000000002}\n",
      "1\n",
      "{'trnq2': 0.529, 'cnum': 2, 'chkq2': 0.437, 'bias': 2.699, 'svrp': 0.050000000000000003, 'threshold': 0.80000000000000004, 'numInp': 87, 'svrc': 2.3000000000000003}\n",
      "2\n",
      "{'trnq2': 0.53, 'cnum': 2, 'chkq2': 0.435, 'bias': 2.66, 'svrp': 0.050000000000000003, 'threshold': 0.80000000000000004, 'numInp': 87, 'svrc': 2.4000000000000004}\n",
      "3\n",
      "{'trnq2': 0.691, 'cnum': 2, 'chkq2': 0.483, 'bias': 3.448, 'svrp': 0.050000000000000003, 'threshold': 0.85000000000000009, 'numInp': 284, 'svrc': 2.1000000000000001}\n",
      "4\n",
      "{'trnq2': 0.694, 'cnum': 2, 'chkq2': 0.483, 'bias': 3.469, 'svrp': 0.050000000000000003, 'threshold': 0.85000000000000009, 'numInp': 284, 'svrc': 2.2000000000000002}\n",
      "5\n",
      "{'trnq2': 0.696, 'cnum': 2, 'chkq2': 0.482, 'bias': 3.491, 'svrp': 0.050000000000000003, 'threshold': 0.85000000000000009, 'numInp': 284, 'svrc': 2.3000000000000003}\n",
      "6\n",
      "{'trnq2': 0.699, 'cnum': 2, 'chkq2': 0.481, 'bias': 3.513, 'svrp': 0.050000000000000003, 'threshold': 0.85000000000000009, 'numInp': 284, 'svrc': 2.4000000000000004}\n",
      "7\n",
      "{'trnq2': 0.814, 'cnum': 2, 'chkq2': 0.565, 'bias': 2.382, 'svrp': 0.050000000000000003, 'threshold': 0.90000000000000013, 'numInp': 860, 'svrc': 2.1000000000000001}\n",
      "8\n",
      "{'trnq2': 0.815, 'cnum': 2, 'chkq2': 0.565, 'bias': 2.38, 'svrp': 0.050000000000000003, 'threshold': 0.90000000000000013, 'numInp': 860, 'svrc': 2.2000000000000002}\n",
      "9\n",
      "{'trnq2': 0.817, 'cnum': 2, 'chkq2': 0.565, 'bias': 2.378, 'svrp': 0.050000000000000003, 'threshold': 0.90000000000000013, 'numInp': 860, 'svrc': 2.3000000000000003}\n",
      "10\n",
      "{'trnq2': 0.818, 'cnum': 2, 'chkq2': 0.564, 'bias': 2.376, 'svrp': 0.050000000000000003, 'threshold': 0.90000000000000013, 'numInp': 860, 'svrc': 2.4000000000000004}\n",
      "11\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "opt = float(\"-inf\")\n",
    "L = []\n",
    "df = pd.DataFrame(L)\n",
    "#df=pd.DataFrame(df, columns=['a/b', 'fs/threshold', 'numInp', 'cnum', 'bias', 'svrc', 'svrp', 'trnq2', 'chkq2'])\n",
    "df=pd.DataFrame(df, columns=['a/b', 'fs/threshold', 'numInp', 'cnum', 'bias', 'svrc', 'svrp', 'trnq2', 'chkq2'])\n",
    "i=0\n",
    "for t in np.arange(0.80, 0.95, 0.05):\n",
    "        \n",
    "    selector = vt(threshold=(t * (1 - t)))\n",
    "    selector.fit_transform(trnin)\n",
    "    selidx = selector.get_support(indices=True)\n",
    "    selfea = selidx\n",
    "    numInp=len(selidx)\n",
    "    \n",
    "    Xtrain = trnin.as_matrix()[:,selfea.tolist()]\n",
    "    Xtrain = pd.DataFrame(Xtrain)\n",
    "    Xtest = chkin.as_matrix()[:,selfea.tolist()]\n",
    "    Xtest = pd.DataFrame(Xtest)\n",
    "    \n",
    "    for cnum in range(2,3):\n",
    "        for svrc in np.arange(2.1, 2.5, 0.1):\n",
    "            for svrp in np.arange(0.05, 0.06, 0.01):\n",
    "                param = {'numInp':numInp, 'cnum':cnum, 'svrc':svrc, 'svrp':svrp, 'threshold':t}\n",
    "                paramnew = repeatprocess(param)\n",
    "                print(paramnew)\n",
    "                if float(paramnew['chkq2'])>opt:\n",
    "                   opt = float(paramnew['chkq2'])\n",
    "                   #df.loc[i] = ['a', t, paramnew['numInp'], paramnew['cnum'], paramnew['bias'], paramnew['svrc'], paramnew['svrp'], paramnew['trnq2'], paramnew['chkq2']]\n",
    "                   df.loc[i] = ['a', t, paramnew['numInp'], paramnew['cnum'], paramnew['bias'], paramnew['svrc'], paramnew['svrp'], paramnew['trnq2'], paramnew['chkq2']]\n",
    "                else:\n",
    "                   #df.loc[i] = ['b', t, paramnew['numInp'], paramnew['cnum'], paramnew['bias'], paramnew['svrc'], paramnew['svrp'], paramnew['trnq2'], paramnew['chkq2']]\n",
    "                   df.loc[i] = ['b', t, paramnew['numInp'], paramnew['cnum'], paramnew['bias'], paramnew['svrc'], paramnew['svrp'], paramnew['trnq2'], paramnew['chkq2']]\n",
    "                df.to_csv('result.csv', encoding='utf-8', index=False)\n",
    "                print(i)\n",
    "                i=i+1\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3799999999999999"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = np.round(float(paramnew['bias']), decimals = 2)\n",
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    5,    6, ..., 5719, 5723, 5748])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selfea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1049,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(selfea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
